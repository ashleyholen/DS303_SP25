---
title: "Qualitative Predictors"
author: 
  - "Ashley Holen"
  - "DS303, SP25"
  - "Prof. Amber Camp"
date: 2/7/25
format: html
editor: visual
theme: spacelab
---

## Qualitative Predictors

So far, we have used the `Boston` data to explore variables that are all numerical/quantitative. In this document, we will examine data that is qualitative in nature.

## Let's try it

Start by loading the `MASS` and `ISLR2` packages, and also `lme4` and `tidyverse`. The `MASS` package is loaded just so we can briefly look at `Boston`, but we will actually be using `Carseats` data from `ISLR2`.

```{r, echo = FALSE, message = FALSE}
library(MASS)
library(ISLR2)
library(lme4)
library(tidyverse)
```

## Boston Housing Data

Take a moment to use the `skimr` package to examine the `Boston` data. You are probably quite familiar with this data at this point.

`skimr` will create a new table for you that summarizes the `Boston` data, including details like number of `NA`s, the mean and sd, etc. Look at the different variables listed in the second column, and the associated type listed in the first column. See how every variable is numeric?

```{r}
# install.packages("skimr") # install if needed
skim_boston <- skimr::skim(Boston)
View(skim_boston)
```

## Carseats data

Use `skimr` to inspect the Carseats data. You should see a few variables of type *factor*. Notice how the mean calculation doesn't apply, and there are new columns for factor information in your `skimr` table.

```{r}
carseats <- Carseats # assign, for easy access later
skim_carseats <- skimr::skim(carseats)
View(skim_carseats)
```

### Examine the categorical data

Examine the factor variables. These are qualitative in nature and are evaluated as ***categorical data***.

Qualitative predictors such as `ShelveLoc` consist of different ***levels*** within that category. ***Levels*** refer to the distinct categories or values that a categorical variable can take. For example, levels of the made-up variable `Fruit` could include apple, banana, and cherry. In the case of `ShelveLoc`, the levels are bad, medium, and good. I'm glad you're reading this and not just looking at the code! Tell me your favorite fruit for an extra point.

**Strawberries!**

By the way, `ShelveLoc` refers to the shelving location for carseats---that is, the place on a store shelf in which the car seat is displayed.

```{r}
summary(carseats$ShelveLoc) # three levels (bad, good, medium)

summary(carseats$Urban) # two levels (no, yes)

summary(carseats$US) # two levels (no, yes)\

head(carseats)
```

### Dummy coding

Given a qualitative variable such as `ShelveLoc`, `R` generates dummy variables automatically. This is referred to as *dummy coding*. We'll spend more time in a future class discussing coding (including dummy coding). Consider this a soft launch.

We can use `contrasts()` to see how the dummy coding is applied.

```{r}
contrasts(carseats$ShelveLoc)
```

Here is how to interpret that matrix.

-   `R` has created a `ShelveLocGood` dummy variable that takes on a value of 1 if the shelving location is **good**, and 0 otherwise.

-   It has also created a `ShelveLocMedium` dummy variable that equals 1 if the shelving location is **medium**, and 0 otherwise.

-   A **bad** shelving location corresponds to a zero for each of the two dummy variables.

### Run a linear regression model.

Let's run a model to see it in action. We will attempt to predict `Sales` based on `ShelveLoc`.

```{r}
lm.shelf <- lm(Sales ~ ShelveLoc, data = carseats)
summary(lm.shelf)
```

### Interpretation of `lm.shelf`

Note that the output does not just say `ShelveLoc` - - you have `ShelveLocGood` and `ShelveLocMedium`. Where is `ShelveLocBad`? It is not listed because it serves as the **reference category** in the model.

This means that the coefficients for `ShelveLocGood` and `ShelveLocMedium` show how much sales increase **compared to** `ShelveLocBad`. We don't need a separate coefficient for `ShelveLocBad` because it is the baseline that the other categories are compared against. We see:

-   The coefficient for `ShelveLocGood` is positive, indicating that a Good shelving location is associated with high sales (relative to a Bad location)

-   `ShelveLocMedium` has a smaller positive coefficient, indicating that a Medium shelving location is associated with higher sales than a bad shelving location, but lower sales than a good shelving location

### Visualization

Scatterplots are not really useful here with the categorical data (try it, you'll see what I mean). Use a boxplot or violin plot instead.

Evaluate the below plots. Do they align with the model interpretation above?

```{r}
ggplot(carseats, aes(x = ShelveLoc, y = Sales)) +
  geom_boxplot() +
  stat_summary(fun = mean, geom = "point", color = "red", size = 2) # red dot shows the mean

ggplot(carseats, aes(x = ShelveLoc, y = Sales)) +
  geom_violin()
```

To inspect your model, you can also create a residuals vs. fitted values plot to check for homoscedasticity (constant variance of residuals) and a Q-Q plot to check if the residuals are normally distributed.

```{r}
# create a new df with residual and predicted values
predicted <- predict(lm.shelf)
residuals <- resid(lm.shelf)
residuals_data <- data.frame(fitted = predicted, residuals = residuals)

# residuals v. fitted values plot
ggplot(residuals_data, aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Residuals vs. Fitted Values",
       x = "Fitted Values",
       y = "Residuals")

# Q-Q plot
ggplot(data.frame(residuals = residuals), aes(sample = residuals)) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "Normal Q-Q Plot of Residuals") +
  theme_minimal()
```

## Your turn

### Predicting Price based on Shelf Location

Below, fit a linear regression model to predict `Price` based on `ShelveLoc`. I'll leave it to you to recall the syntax and build your model.

```{r}
lm.price <- lm(Price ~ ShelveLoc, data = carseats)
summary(lm.price)
```

Create a boxplot or violin plot to aid in your interpretation, and write in your interpretation below.

```{r}
# boxplot here
ggplot(carseats, aes(x = ShelveLoc, y = Price)) +
  geom_boxplot() +
  stat_summary(fun = mean, geom = "point", color = "red", size = 2)
```

#### Interpretation of `lm.price`

**lm.price is a linear model that predicts Price based on ShelveLoc in the carseats dataset. As explained earlier, coefficients for `ShelveLocGood` and `ShelveLocMedium` show how much sales increase compared to `ShelveLocBad`. The Good coefficient is positive 3.612, and the Medium coefficient is positive 1.382. This shows that Good has the highest price, while Medium has a smaller positive coefficient so it is lower that Good but higher than Bad. The Bad category has the lowest price. This is modeled in the box plot, as it can be seen that especially the means are relatively close together, but in the order of Good, Medium, Bad in reference to Price. On average, Good has a 3.612 higher price than Bad, and Medium has 1.382 higher price than Bad. The intercept of 144.271 is statistically significant.**

### Predict Sales using all variables

Below, fit a linear regression model to predict `Sales` that includes ALL variables as well as a few interaction terms of your choice.

```{r}
lm.carseats <- lm(Sales ~ . + Population:Age + Income:Advertising, data = carseats)
summary(lm.carseats)

```

#### Interpretation of `lm.carseats`

Provide a summary of the model output, including key coefficients and their significance levels. Discuss which variables are statistically significant predictors of `Sales`.

**Looking at the model output, it can be seen visually that the key coefficients of this model are the intercept, CompPrice (increases along with sales), Income (increases along with sales), Advertising (slightly less) (increases along with sales), Price (increases and sales decreases), ShelveLocGood (increases along with sales), ShelveLocMedium (increases along with sales), Age (increases and sales decreases), and the Income:Advertising (slightly less) (increases along with sales). Other key findings are the high f statistic and low p value, showing that the model as a whole is statistically significant. The multiple r-squared shows that the model accounts for about 87.6% of the variability of Sales.** **The variable that has the greatest effect on Sales is ShelveLocGood.**

#### Practical implications

Discuss the practical implications of your findings. How can this model inform business decisions regarding pricing, advertising, or product placement, etc?

**This model can definitely be applied in a business setting to increase sales. It was found that lowering the price increases sales, placing products on a good shelf causes higher sales, more advertising leads to higher sales, older customers purchase less, and price increases of competitors will also increase the prices of the business. The model can additionally be analyzed further to understand the extent to which each variable effects sales.**
